{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whsg1XX_OZs6"
      },
      "source": [
        "# Boilerplate\n",
        "\n",
        "Packae installation, loading, and dataloaders. There's also a simple model defined. You can change it your favourite architecture if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3c0QWud9cXg",
        "outputId": "0eb72a6d-75c0-4abe-95ef-4fb8a90dc069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1domTvnONqD",
        "outputId": "bdc7077b-2a94-42d2-aa47-04f74c0600cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Normalize()\n",
              "  (1): Net(\n",
              "    (fc): Linear(in_features=784, out_features=200, bias=True)\n",
              "    (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "## Simple NN. You can change this if you want.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(28*28, 200)\n",
        "        self.fc2 = nn.Linear(200,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view((-1, 28*28))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return (x - 0.1307)/0.3081\n",
        "\n",
        "# Add the data normalization as a first \"layer\" to the network\n",
        "# this allows us to search for adverserial examples to the real image, rather than\n",
        "# to the normalized image\n",
        "model = nn.Sequential(Normalize(), Net())\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCmWfZHTO8Oo"
      },
      "source": [
        "# Implement the Attacks\n",
        "\n",
        "Functions are given a simple useful signature that you can start with. Feel free to extend the signature as you see fit.\n",
        "\n",
        "You may find it useful to create a 'batched' version of PGD that you can use to create the adversarial attack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZjvA49yONqP"
      },
      "outputs": [],
      "source": [
        "# The last argument 'targeted' can be used to toggle between a targeted and untargeted attack.\n",
        "# We want to maximize loss for an input for an untargeted attack.\n",
        "def fgsm_untargeted(model, x, eps, targeted=False): # x is a list of (input, correct output) pairs\n",
        "  ''' Just Untargeted '''\n",
        "  outputs = []\n",
        "  number_of_attacks = 0\n",
        "  L = nn.CrossEntropyLoss()\n",
        "  for ip,op in x:\n",
        "    ip.requires_grad_()\n",
        "    loss = L(model(ip), torch.tensor([op], dtype=torch.long))\n",
        "    loss.backward()\n",
        "    nu = eps*torch.sign((ip.grad))\n",
        "    fgsm_ip = ip + nu\n",
        "    fgsm_op = model(fgsm_ip).argmax(dim=1).item()\n",
        "    outputs.append((op,fgsm_op))\n",
        "    if op != fgsm_op:\n",
        "      number_of_attacks = number_of_attacks + 1\n",
        "  robustness = (1 - (number_of_attacks/len(x)))*100\n",
        "  return outputs, robustness\n",
        "\n",
        "def project(y,x,eps):\n",
        "  return torch.clamp(y, torch.add(x, -eps), torch.add(x, eps))\n",
        "\n",
        "# def pgd_untargeted(model, x, labels, k, eps, eps_step):\n",
        "\n",
        "# def pgd_untargeted(model, x, k, eps, eps_step):\n",
        "#   outputs = []\n",
        "#   number_of_attacks = 0\n",
        "#   L = nn.CrossEntropyLoss()\n",
        "#   for ip, op in x:\n",
        "#     ipk = ip\n",
        "#     ipk.requires_grad_()\n",
        "#     for i in range(k):\n",
        "#       loss = L(model(ipk), torch.tensor([op], dtype=torch.long))\n",
        "#       ipk.retain_grad()\n",
        "#       loss.backward(retain_graph=True)\n",
        "#       nu = eps_step*torch.sign((ipk.grad))\n",
        "#       ipk = project(ipk+nu, ip, eps)\n",
        "#       # ipk.retain_grad()\n",
        "#       fgsm_op = model(ipk).argmax(dim=1).item()\n",
        "\n",
        "#       outputs.append((op,fgsm_op))\n",
        "#       if op != fgsm_op:\n",
        "#         number_of_attacks = number_of_attacks + 1\n",
        "#         break # found attack\n",
        "#   robustness = (1 - (number_of_attacks/len(x)))*100\n",
        "#   return outputs, robustness\n",
        "\n",
        "\n",
        "\n",
        "def pgd_untargeted(model, x, k, eps, eps_step):\n",
        "\n",
        "  outputs = []\n",
        "  number_of_attacks = 0\n",
        "\n",
        "  L = nn.CrossEntropyLoss()\n",
        "  for ip, op in x:\n",
        "    ipk = ip\n",
        "    ip.requires_grad_()\n",
        "\n",
        "    loss = L(model(ipk), torch.tensor([op], dtype=torch.long))\n",
        "    ipk.retain_grad()\n",
        "    loss.backward(retain_graph = True)\n",
        "    worstcase, worstloss = ipk, loss\n",
        "    for j in range(k):\n",
        "      nu = eps_step*torch.sign((ipk.grad))\n",
        "      ipk = project(ipk+nu, ip, eps)\n",
        "\n",
        "      loss = L(model(ipk), torch.tensor([op], dtype=torch.long))\n",
        "      ipk.retain_grad()\n",
        "      loss.backward(retain_graph = True)\n",
        "\n",
        "      if abs(loss) > worstloss:\n",
        "        worstcase, worstloss = ipk, loss\n",
        "\n",
        "\n",
        "    worstcase_output = model(ipk).argmax(dim=1).item()\n",
        "    if op != worstcase_output:\n",
        "      number_of_attacks = number_of_attacks + 1\n",
        "      outputs.append((worstcase,op))   #\n",
        "  robustness = (1 - (number_of_attacks/len(x)))*100\n",
        "  return outputs, robustness\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtd69Sgsu9Sa"
      },
      "source": [
        "Accuracy on test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfoU-Up883ST",
        "outputId": "5893f9ad-2720-4eee-cd5d-d8f2c05c3b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy(percentage): 10.22\n"
          ]
        }
      ],
      "source": [
        "# Testing accuracy of the model\n",
        "\n",
        "def accuracy(model, test_set = test_dataset):\n",
        "  correct = 0\n",
        "  for ip,op in test_set:\n",
        "    if model(ip).argmax(dim=1).item() == op:\n",
        "      correct = correct + 1\n",
        "  return (correct/len(test_set))*100\n",
        "\n",
        "print('Accuracy(percentage):',accuracy(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN6NJHWIudmS"
      },
      "source": [
        "Initial Attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ70TlCEuZvC",
        "outputId": "18de23f8-4945-4213-f386-e5f616a8f60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percent of examples where FGSM attack was not found: 2.1700000000000053\n",
            "Percent of examples where PGD attack was not found: 2.1299999999999986\n"
          ]
        }
      ],
      "source": [
        "print('Percent of examples where FGSM attack was not found:',fgsm_untargeted(model, test_dataset, 0.01, False)[1])\n",
        "print('Percent of examples where PGD attack was not found:', pgd_untargeted(model, test_dataset, 3, 0.01, 0.005)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mja_AB4RykO"
      },
      "source": [
        "# Implement Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-sw8yKYONqQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, enable_defense=True):\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    tot_steps = 0\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        t1 = time.time()\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "\n",
        "            if enable_defense:\n",
        "              x = list(zip(x_batch, y_batch))\n",
        "              worstcase = pgd_untargeted(model, x, 10, 0.01, 0.005)[0] # this does not necessarily find the worst loss in the eps-ball around inputs, but it does find some bad loss.\n",
        "              if len(worstcase) != 0:\n",
        "                worst_ip, op = [list(i) for i in zip(*worstcase)]       # bad input list and the outputs needed for robustness\n",
        "                # worst_ip, op = worst_ip.to(device), op.to(device)  # op is just y_batch\n",
        "                opt.zero_grad()\n",
        "                out = model(torch.stack(worst_ip, dim=0))\n",
        "                batch_loss = ce_loss(out, torch.stack(op, dim=0))\n",
        "                batch_loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            tot_steps += 1\n",
        "            opt.zero_grad()\n",
        "            out = model(x_batch)\n",
        "            batch_loss = ce_loss(out, y_batch)\n",
        "            batch_loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        tot_test, tot_acc = 0.0, 0.0\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            out = model(x_batch)\n",
        "            pred = torch.max(out, dim=1)[1]\n",
        "            acc = pred.eq(y_batch).sum().item()\n",
        "            tot_acc += acc\n",
        "            tot_test += x_batch.size()[0]\n",
        "        t2 = time.time()\n",
        "\n",
        "        print('Epoch %d: Accuracy %.5lf [%.2lf seconds]' % (epoch, tot_acc/tot_test, t2-t1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3pLyiFo1oIg"
      },
      "source": [
        "Training (first run the file with enable_defense turned off, then onn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m9I4L2gE1l5R",
        "outputId": "b6f6bada-4d9e-4520-bd5c-54d1a21f4237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Accuracy 0.94200 [473.35 seconds]\n",
            "Epoch 2: Accuracy 0.95480 [472.19 seconds]\n",
            "Epoch 3: Accuracy 0.96360 [473.92 seconds]\n"
          ]
        }
      ],
      "source": [
        "train_model(model, 3, enable_defense=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5IXVWh01jLz"
      },
      "source": [
        "After training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eQh-uptpBxK2",
        "outputId": "58aa9d61-f7c4-47d2-a764-e7ab77232a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy(percentage): 96.36\n",
            "Percent of examples where FGSM attack was not found: 93.77\n",
            "Percent of examples where PGD attack was not found: 93.72\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy(percentage):',accuracy(model))\n",
        "print('Percent of examples where FGSM attack was not found:',fgsm_untargeted(model, test_dataset, 0.01, False)[1])\n",
        "print('Percent of examples where PGD attack was not found:', pgd_untargeted(model, test_dataset, 3, 0.01, 0.005)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPMdfEhtR3zm"
      },
      "source": [
        "# Study Accuracy, Quality, etc.\n",
        "\n",
        "Compare the various results and report your observations on the submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ufD-ccTFR8R2"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python3 (ml)",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}