{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0_a0Z-xvNdC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.optim as optim\n",
        "# from collections import OrderedDict\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDzCEmqvv5U1",
        "outputId": "164831b1-c5ea-422b-cad7-9f8b719d8af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class NN(nn.Module):\n",
        "#   '''\n",
        "#   NN with 3 hidden layers each of 50 neurons each.\n",
        "#   Input is 28*28 image\n",
        "#   '''\n",
        "#   def __init__(self):\n",
        "#       super().__init__()\n",
        "#       self.flatten = nn.Flatten()\n",
        "#       self.linear_relu_stack = nn.Sequential(OrderedDict([\n",
        "#           ('w01', nn.Linear(28*28, 50)),\n",
        "#           ('r1', nn.ReLU()),\n",
        "#           ('w12', nn.Linear(50, 50)),\n",
        "#           ('r2', nn.ReLU()),\n",
        "#           ('w23', nn.Linear(50, 50)),\n",
        "#           ('r3', nn.ReLU()),\n",
        "#           ('w34', nn.Linear(50, 10))\n",
        "#       ])\n",
        "#       )\n",
        "\n",
        "#   def forward(self, x):\n",
        "#       x = self.flatten(x)\n",
        "#       logits = self.linear_relu_stack(x)\n",
        "#       return logits\n"
      ],
      "metadata": {
        "id": "d8rmNLPkwKMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.w01 = nn.Linear(28*28, 50)\n",
        "        self.r1 = nn.ReLU()\n",
        "        self.w12 = nn.Linear(50,50)\n",
        "        self.r2 = nn.ReLU()\n",
        "        self.w23 = nn.Linear(50,50)\n",
        "        self.r3 = nn.ReLU()\n",
        "        self.w34 = nn.Linear(50,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = x.view((-1, 28*28))\n",
        "        x = self.w01(x)\n",
        "        x = self.r1(x)\n",
        "        x = self.w12(x)\n",
        "        x = self.r2(x)\n",
        "        x = self.w23(x)\n",
        "        x = self.r3(x)\n",
        "        x = self.w34(x)\n",
        "        return x\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return (x - 0.1307)/0.3081\n",
        "\n",
        "# Add the data normalization as a first \"layer\" to the network\n",
        "# this allows us to search for adverserial examples to the real image, rather than\n",
        "# to the normalized image\n",
        "model = nn.Sequential(Normalize(), NN())\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVQU9_KjD-hK",
        "outputId": "4a61b32c-465b-440d-e392-89e545aede15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Normalize()\n",
              "  (1): NN(\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    (w01): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (r1): ReLU()\n",
              "    (w12): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (r2): ReLU()\n",
              "    (w23): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (r3): ReLU()\n",
              "    (w34): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfqX0JNoyPVx",
        "outputId": "c825b306-1e24-4c5e-9b2f-db7fbb2b0561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (w01): Linear(in_features=784, out_features=50, bias=True)\n",
            "  (r1): ReLU()\n",
            "  (w12): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (r2): ReLU()\n",
            "  (w23): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (r3): ReLU()\n",
            "  (w34): Linear(in_features=50, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data\n"
      ],
      "metadata": {
        "id": "S5c5lqj81NDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "# np.random.seed(42)\n",
        "# torch.manual_seed(42)\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "XDs5EwtW0_rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b060718-e175-4da2-f3d5-5f4406bb66ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 88310148.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 87525790.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26412661.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5372399.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "Bp81Whh5CMAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, num_epochs, enable_defense=True):\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    tot_steps = 0\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        t1 = time.time()\n",
        "\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "          tot_steps += 1\n",
        "          opt.zero_grad()\n",
        "          out = model(x_batch)\n",
        "          batch_loss = ce_loss(out, y_batch)\n",
        "          batch_loss.backward()\n",
        "          opt.step()\n",
        "\n",
        "        tot_test, tot_acc = 0.0, 0.0\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            out = model(x_batch)\n",
        "            pred = torch.max(out, dim=1)[1]\n",
        "            acc = pred.eq(y_batch).sum().item()\n",
        "            tot_acc += acc\n",
        "            tot_test += x_batch.size()[0]\n",
        "        t2 = time.time()\n",
        "\n",
        "        print('Epoch %d: Accuracy %.5lf [%.2lf seconds]' % (epoch, tot_acc/tot_test, t2-t1))"
      ],
      "metadata": {
        "id": "E3ri9PKmB-1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box operations:"
      ],
      "metadata": {
        "id": "UzWoUNk1E1AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def box_add(*boxes):\n",
        "  add_a, add_b = 0, 0\n",
        "  for a,b in boxes:\n",
        "    add_a = add_a + a\n",
        "    add_b = add_b + b\n",
        "  return (add_a, add_b)\n",
        "\n",
        "def box_scalarmult(alpha, box):\n",
        "  a, b = box\n",
        "  return (alpha*a, alpha*b) if alpha >= 0 else (alpha*b, alpha*a)\n",
        "\n",
        "def box_affine(layer, boxes):\n",
        "      '''\n",
        "      wi are the weights going into the ith neuron in the next layer.\n",
        "      wi[j]*box[j] gives the box abstraction of the edge from the jth neuron on the current layer to the ith neuron of the next.\n",
        "      Sum over all wi[j] to get the box of the ith neuron of the next layer.\n",
        "      '''\n",
        "      weights = layer.weight\n",
        "      next_boxes = []\n",
        "      for wi in weights:\n",
        "        next_boxes.append(box_add(*[box_scalarmult(wi[j], boxes[j]) for j in range(len(weights))]))\n",
        "\n",
        "      return next_boxes\n",
        "\n",
        "def box_relu(boxes):\n",
        "  def box_relu1(box):\n",
        "    a, b = box\n",
        "    ra = 0 if a <= 0 else a\n",
        "    rb = 0 if b <= 0 else b\n",
        "    return (ra, rb)\n",
        "  return [box_relu1(box) for box in boxes]\n",
        "\n",
        "\n",
        "lower = 0\n",
        "upper = 1\n",
        "\n",
        "def box_lu_tensorify(boxes, mode = 0):\n",
        "  '''\n",
        "  (...,[li,ui],...) -> tensor([...li...]), tensor([...ui...])\n",
        "  mode = 0 gives lower bounds\n",
        "  mode = 1 gives upper bounds\n",
        "  '''\n",
        "  if mode == 0:\n",
        "    m = [l for (l,u) in boxes]\n",
        "    return torch.FloatTensor(m)\n",
        "  else:\n",
        "    m = [u for (l,u) in boxes]\n",
        "    return torch.FloatTensor(m)\n",
        "\n",
        "\n",
        "def box_indexed_tensorify(boxes, index):\n",
        "  '''\n",
        "  Return a tensor which has the upper bound for all indeces that isn't 'index'.\n",
        "  Lower bound for index.\n",
        "  '''\n",
        "  indexed_list = []\n",
        "  for i, box in enumerate(boxes):\n",
        "    if i != index:\n",
        "      indexed_list.append(box[1])\n",
        "    else:\n",
        "      indexed_list.append(box[0])\n",
        "  return torch.FloatTensor(indexed_list)\n",
        "\n",
        "\n",
        "def tensor_boxify(tensor, eps):\n",
        "  '''\n",
        "  [tensor([...x..]) -> [...(x-eps,x+eps)...]\n",
        "  '''\n",
        "  boxes = []\n",
        "  t1 = tensor.tolist()\n",
        "  for x in t1:\n",
        "    boxes.append((x-eps,x+eps))\n",
        "  return boxes\n",
        "\n",
        "\n",
        "# def box_isindex(boxes, index):\n",
        "#   '''\n",
        "#   To check if classified as index.\n",
        "#   Checks if min(box[i])>max(box[j]) for every j != i\n",
        "#   '''\n",
        "#   min_index = boxes[i][0]\n",
        "#   is_index = True\n",
        "\n",
        "#   for i in range(len(boxes)):\n",
        "#     if i != index:\n",
        "#       if min_index <= boxes[i][1]:\n",
        "#             is_index = False\n",
        "#             break\n",
        "#   return is_index"
      ],
      "metadata": {
        "id": "p7YrNIQWelB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def box_nn(input_boxes, model):\n",
        "  '''\n",
        "  Inputs of the NN as boxes. Returns boxes of output (modulo softmax)\n",
        "  '''\n",
        "  w01 = model.w01\n",
        "  w12 = model.w12\n",
        "  w23 = model.w23\n",
        "  w34 = model.w34\n",
        "\n",
        "  boxes = box_relu( box_affine(w01, input_boxes)  )\n",
        "  boxes = box_relu( box_affine(w12, boxes)  )\n",
        "  boxes = box_relu( box_affine(w23, boxes)  )\n",
        "  boxes = box_relu( box_affine(w34, boxes)  )\n",
        "\n",
        "  return boxes"
      ],
      "metadata": {
        "id": "j87WceE_IZ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2(a)"
      ],
      "metadata": {
        "id": "LQp_QSD81XfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def robustness(model, test_set, eps):\n",
        "  '''\n",
        "  Given a model and a test set with input, ground truth (x,y),\n",
        "  check if the L_infty eps ball around x also gives y.\n",
        "\n",
        "  Using boxes, we get a range of losses. See if inputs are robust.\n",
        "  Also find the maximum loss amongst these and average out amongst no. of xs.\n",
        "  '''\n",
        "  sum_loss = 0\n",
        "  number_of_robust_inputs = 0\n",
        "  for input_tensor, ground_index in test_set:\n",
        "    input_boxes = tensor_boxify(torch.flatten(input_tensor), eps)\n",
        "\n",
        "    output_boxes = box_nn(input_boxes, model)\n",
        "\n",
        "    output_tensor = box_indexed_tensorify(output_boxes, ground_index) # This gives a worst case scenario loss (where ground_index is minimized)\n",
        "                                                                      # and the others are maximized within our abstraction.\n",
        "\n",
        "    if torch.argmax(output_tensor) == ground_index:\n",
        "      number_of_robust_inputs += 1\n",
        "\n",
        "    # max_loss = nn.CrossEntropyLoss(output_tensor, torch.tensor([ground_index], dtype = torch.long)) # worst_case loss\n",
        "    # sum_loss = sum_loss + max_loss\n",
        "\n",
        "  return (number_of_robust_inputs/len(test_set))*100\n",
        "      # , (sum_loss/len(test_set))*100 # robustness and expected max loss\n"
      ],
      "metadata": {
        "id": "eKniF6KFnpn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIsqtnnlBvUR",
        "outputId": "58972db9-6765-4a07-8b17-822216fd2620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy 0.86440 [11.29 seconds]\n",
            "Epoch 2: Accuracy 0.89900 [11.59 seconds]\n",
            "Epoch 3: Accuracy 0.90880 [10.84 seconds]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,11):\n",
        "  print(f'Robustness {robustness(model, test_dataset, 0.1*i)} for eps = {0.1*i}')"
      ],
      "metadata": {
        "id": "odQUR3HvEhpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}